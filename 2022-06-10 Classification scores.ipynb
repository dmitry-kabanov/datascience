{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75efe50-e8b8-4a64-8a55-5cba5580f507",
   "metadata": {},
   "source": [
    "# Classification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "950f740f-c506-41ad-9f1d-3c3cf36cc035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47648c31-2747-4003-bdc9-8fd292e2d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIRPLANE = 1\n",
    "BOAT = 2\n",
    "CAR = classification_reportSES = [AIRPLANE, BOAT, CAR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5108408-2667-4887-9ce4-f45b1f9b4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = np.array([AIRPLANE, CAR, CAR, CAR, CAR, AIRPLANE, BOAT, CAR, AIRPLANE, CAR])\n",
    "predicted = np.array([AIRPLANE, BOAT, CAR, CAR, BOAT, BOAT, BOAT, AIRPLANE, AIRPLANE, CAR])\n",
    "\n",
    "assert len(actual) == len(predicted)\n",
    "\n",
    "assert all([a in CLASSES for a in actual])\n",
    "assert all([p in CLASSES for p in predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b28406c6-8b96-4386-8fbc-1ca01786746e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.67      0.67         3\n",
      "           2       0.25      1.00      0.40         1\n",
      "           3       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.60        10\n",
      "   macro avg       0.64      0.72      0.58        10\n",
      "weighted avg       0.82      0.60      0.64        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88370b2e-d446-4a56-af91-ad20d7245314",
   "metadata": {},
   "source": [
    "We can see that we have imbalanced classes, as boat has only one example, while car has 6 examples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11d6c4d5-7ec0-4b7c-b4f0-b5e889f272f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f99b0-afc3-4580-84f7-4a4daed045c7",
   "metadata": {},
   "source": [
    "From the confustion matrix above we can see that objects of type AIRPLANE (first row) were correctly classified two times, once they were misclassified as BOAT, and zero times as CAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56d6b111-aa6c-4eba-9379-d1f8b70a54d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for AIRPLANE class: TP = 2, FP = 1, FN = 1\n"
     ]
    }
   ],
   "source": [
    "TP_AIRPLANE, FP_AIRPLANE, FN_AIRPLANE = 0, 0, 0\n",
    "\n",
    "for i in range(len(actual)):\n",
    "    if actual[i] == AIRPLANE:\n",
    "        if actual[i] == predicted[i]:\n",
    "            TP_AIRPLANE += 1\n",
    "        else:\n",
    "            FN_AIRPLANE += 1\n",
    "            \n",
    "    if predicted[i] == AIRPLANE and actual[i] != AIRPLANE:\n",
    "        FP_AIRPLANE += 1\n",
    "        \n",
    "print(\"Scores for AIRPLANE class: TP = {}, FP = {}, FN = {}\".format(TP_AIRPLANE, FP_AIRPLANE, FN_AIRPLANE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a12b7f13-2cc6-44ec-a83b-e9d725eac101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airplane metrics: P = 0.666667, R = 0.666667, F1 = 0.666667\n"
     ]
    }
   ],
   "source": [
    "P_AIRPLANE = TP_AIRPLANE / (TP_AIRPLANE + FP_AIRPLANE)\n",
    "R_AIRPLANE = TP_AIRPLANE / (TP_AIRPLANE + FN_AIRPLANE)\n",
    "F1_AIRPLANE = 2 / (1 / P_AIRPLANE + 1 / R_AIRPLANE)\n",
    "\n",
    "print(\"Airplane metrics: P = {:f}, R = {:f}, F1 = {:f}\".format(P_AIRPLANE, R_AIRPLANE, F1_AIRPLANE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a835ba88-dacc-4039-a87d-de6aca717272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dima/dev/learn/data-science'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002f896-841e-4150-b599-205efb76cba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
