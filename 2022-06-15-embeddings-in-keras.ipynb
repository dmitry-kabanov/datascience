{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022-06-15 Embeddings in Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6oEGqVSFlD76uQYwn/zvR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmitry-kabanov/datascience/blob/main/2022-06-15-embeddings-in-keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings in Keras"
      ],
      "metadata": {
        "id": "cbCofqdrpJpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5WP_O5hipMzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a simple model based on embedding layer:"
      ],
      "metadata": {
        "id": "VZMJcW84pbDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(\n",
        "    Embedding(\n",
        "        input_dim=10,   # Size of the input vocabulary\n",
        "        output_dim=4,   # Dimensionality of output vector space\n",
        "        input_length=2  # Maximum length of a sequence\n",
        "    )\n",
        ")\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")"
      ],
      "metadata": {
        "id": "gxxOb9tZpewD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBx9-cBWpuD0",
        "outputId": "e11e49a8-2ffa-4b6f-d867-a89830b048e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 2, 4)              40        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40\n",
            "Trainable params: 40\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of decomposition of words with randomly initialized model"
      ],
      "metadata": {
        "id": "rGI80FPTrIjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we take some indexed input data and embed them with the model:"
      ],
      "metadata": {
        "id": "z4dwGFicp4IS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = np.array([[1, 2]])\n",
        "pred = model.predict(input_data)\n",
        "print(\"Input data shape: \", input_data.shape)\n",
        "print(\"Predictions\")\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aumkCIvqdYe",
        "outputId": "feec8f52-d7b1-427d-f8fc-23b87ff0f790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data shape:  (1, 2)\n",
            "Predictions\n",
            "[[[-0.04194342 -0.03313633 -0.00573406  0.03623357]\n",
            "  [-0.00629203 -0.02213107 -0.0070897   0.01656753]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0].trainable_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx3oqHMaqmlQ",
        "outputId": "3cb404b0-40c6-493c-fe53-82ad9b1c326f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'embedding/embeddings:0' shape=(10, 4) dtype=float32, numpy=\n",
              " array([[ 0.04158003,  0.04614941,  0.01253562,  0.03269812],\n",
              "        [-0.04194342, -0.03313633, -0.00573406,  0.03623357],\n",
              "        [-0.00629203, -0.02213107, -0.0070897 ,  0.01656753],\n",
              "        [-0.01223986, -0.02374547, -0.04237936, -0.04358562],\n",
              "        [-0.02551185,  0.01600123,  0.03523505, -0.03985095],\n",
              "        [-0.04595212,  0.0114981 ,  0.00273025, -0.01366209],\n",
              "        [ 0.04968718,  0.00606449,  0.02919232,  0.01792708],\n",
              "        [ 0.00782752,  0.04510366, -0.03712968,  0.00625715],\n",
              "        [ 0.01315261, -0.01916968,  0.01093953,  0.02169173],\n",
              "        [ 0.01646555, -0.01309564, -0.02450665, -0.04531604]],\n",
              "       dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training embedding model"
      ],
      "metadata": {
        "id": "Cmrh1AXBqs0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get word embeddings, we need to do the following:\n",
        "\n",
        "1. We split sentences into words (tokenization)\n",
        "2. One-hot encode the words\n",
        "3. Pad sequences if needed such that they all are of the same length\n",
        "4. Pass the padded sequences as inputs for model training.\n",
        "5. Flatten and apply a dense layer to predict the label."
      ],
      "metadata": {
        "id": "r7_1Sk5WrbcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Embedding, Dense"
      ],
      "metadata": {
        "id": "Veud_UJzr1-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define 10 resturant reviews as data\n",
        "reviews = [\n",
        "           \"Never coming back!\",\n",
        "           \"horrible service\",\n",
        "           \"rude waitress\",\n",
        "           \"cold food\",\n",
        "           \"horrible food!\",\n",
        "           \"awesome\",\n",
        "           \"awesome services!\",\n",
        "           \"rocks\",\n",
        "           \"poor work\",\n",
        "           \"couldn\\'t have done better\",\n",
        "]\n",
        "\n",
        "# Lables: 1 is negative and 0 is positive\n",
        "labels = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
      ],
      "metadata": {
        "id": "0jHGq-1UsFUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50\n",
        "encoded_reviews = [one_hot(d, vocab_size) for d in reviews]\n",
        "print(f\"Encoded review: {encoded_reviews}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvwwQq9gse5I",
        "outputId": "1be34e51-506c-42dc-d3ee-708c10bbfabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded review: [[24, 17, 45], [5, 49], [46, 29], [43, 23], [5, 23], [36], [36, 44], [33], [44, 20], [32, 45, 1, 38]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "padded_reviews = pad_sequences(\n",
        "    encoded_reviews, maxlen=max_length, padding=\"post\"\n",
        ")\n",
        "print(padded_reviews)"
      ],
      "metadata": {
        "id": "v5ZJbJg9smrh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6dadf2f-e7e1-4d33-ed65-2a22ca2705a6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[24 17 45  0]\n",
            " [ 5 49  0  0]\n",
            " [46 29  0  0]\n",
            " [43 23  0  0]\n",
            " [ 5 23  0  0]\n",
            " [36  0  0  0]\n",
            " [36 44  0  0]\n",
            " [33  0  0  0]\n",
            " [44 20  0  0]\n",
            " [32 45  1 38]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model for embedding will be such that the resultant vectors are in 8-dimensional space, with input vocabulary size `vocab_size` and input sequence\n",
        "length `max_length`:"
      ],
      "metadata": {
        "id": "cEdvFXzVJwXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=8, input_length=max_length),\n",
        "    Flatten(),\n",
        "    Dense(1, activation=\"sigmoid\"),\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-pJilPqKqeB",
        "outputId": "482c9237-f665-4793-82af-15fcfca1f6df"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 4, 8)              400       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 433\n",
            "Trainable params: 433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(padded_reviews, labels, epochs=100, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha9IHWU4LF57",
        "outputId": "6d390aea-b93d-4155-889a-abdb026ebd3a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2c35f27f50>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].get_weights()[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-smejkgWLNO7",
        "outputId": "412c1922-8500-489d-8275-c0d1954d1be1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].get_weights()[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OVap0p2LVfJ",
        "outputId": "2fe38d71-de1f-47bc-d3e6-c798e6acb704"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.1151866   0.11104467  0.15172915 -0.1234385  -0.12647197  0.07070275\n",
            " -0.09507612 -0.15376773]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QMoE778OLfVu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}